{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API - Alpha Vantage: QCK77CCG334FOMUM\n",
    "# API - Market News: 65FA39D2A26E42A89E83AAFBA8F1D1F7\n",
    "NewsAPI_NS = 'ec85fab4b1e1403596b9a6a7ca364362'\n",
    "NewsAPI_MR = 'a539d7df2c7b43e1ac4d12f386d901e8'\n",
    "NewsAPI_JT = 'baf866b3db234223aaf395e94104530f'\n",
    "AlphaVantage_Api_key = 'QCK77CCG334FOMUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from newsapi import NewsApiClient\n",
    "from iexfinance import Stock\n",
    "from iexfinance import get_historical_data\n",
    "from datetime import datetime\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests\n",
    "import string\n",
    "import re \n",
    "import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# response = requests.get(\"https://globalnews.xignite.com/xGlobalNews.json/ListSectors?&_token=65FA39D2A26E42A89E83AAFBA8F1D1F7\")\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the api keys for Mark and Naoko\n",
    "newsapi_ns = NewsApiClient(api_key=NewsAPI_NS)\n",
    "newsapi_mr = NewsApiClient(api_key=NewsAPI_MR)\n",
    "newsapi_jt = NewsApiClient(api_key=NewsAPI_JT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_source = [item['id'] for item in newsapi_ns.get_sources()['sources']]\n",
    "selected_list_of_source =['abc-news', 'business-insider', 'google-news', 'reuters', 'nbc-news','the-new-york-times', 'techcrunch', 'wired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netflix\n",
    "# pull the news articles (abc news) for Netflix\n",
    "apple_abc = []\n",
    "for i in range (1,51):\n",
    "    page = newsapi_ns.get_everything(q='Netflix',sort_by = 'publishedAt',language='en', from_param = '2018-08-22', to = '2018-08-29', page = i, sources = selected_list_of_source[0])\n",
    "    if len(page) != 0:\n",
    "        apple_abc.append(page['articles'])\n",
    "# pull the news articles (business insider) for Netflix from NewsAPI\n",
    "apple_business_insider = []\n",
    "for i in range (1,51):\n",
    "    page = newsapi_ns.get_everything(q='Netflix',sort_by = 'publishedAt',language='en', from_param = '2018-08-22', to = '2018-08-29', page = i, sources = selected_list_of_source[1])\n",
    "    if len(page) != 0:\n",
    "        apple_business_insider.append(page['articles'])\n",
    "# pull the news articles (reuters) for Netflix from NewsAPI\n",
    "apple_reuters = []\n",
    "for i in range (1,51):\n",
    "    page = newsapi_ns.get_everything(q='Netflix',sort_by = 'publishedAt',language='en', from_param = '2018-08-22', to = '2018-08-29', page = i, sources = selected_list_of_source[3])\n",
    "    if page != []:\n",
    "        apple_reuters.append(page['articles'])\n",
    "# pull the news articles (nbc-news) for Netflix from NewsAPI\n",
    "apple_nbc_news = []\n",
    "for i in range (1,51):\n",
    "    page = newsapi_ns.get_everything(q='Netflix',sort_by = 'publishedAt',language='en', from_param = '2018-08-22', to = '2018-08-29', page = i, sources = selected_list_of_source[4])\n",
    "    if page != []:\n",
    "        apple_nbc_news.append(page['articles'])       \n",
    "# pull the news articles (techcrunch) for Netflix from NewsAPI\n",
    "apple_techcrunch = []\n",
    "for i in range (1,51):\n",
    "    page = newsapi_ns.get_everything(q='Netflix',sort_by = 'publishedAt',language='en', from_param = '2018-08-22', to = '2018-08-29', page = i, sources = selected_list_of_source[6])\n",
    "    if page != []:\n",
    "        apple_techcrunch.append(page['articles'])\n",
    "# pull the news articles (new york times) for Netflix from NewsAPI\n",
    "apple_nyt = []\n",
    "for i in range (1,31):\n",
    "    page = newsapi_jt.get_everything(q='Netflix',sort_by = 'publishedAt',language='en', from_param = '2018-08-22', to = '2018-08-29', page = i, sources = selected_list_of_source[5])\n",
    "    if page != []:\n",
    "        apple_nyt.append(page['articles'])    \n",
    "# pull the news articles (wired) for Apple from NewsAPI\n",
    "apple_wired = []\n",
    "for i in range (1,31):\n",
    "    page = newsapi_jt.get_everything(q='Netflix',sort_by = 'publishedAt',language='en', from_param = '2018-08-22', to = '2018-08-29', page = i, sources = selected_list_of_source[7])\n",
    "    if page != []:\n",
    "        apple_wired.append(page['articles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all the articles in one list - apple\n",
    "apple_article_abc_all = [apple_abc[i][j] for i in range(0, len(apple_abc)) for j in range(0, len(apple_abc[i]))]\n",
    "apple_article_business_insider_all = [apple_business_insider[i][j] for i in range(0, len(apple_business_insider)) for j in range(0, len(apple_business_insider[i]))]\n",
    "apple_article_reuters_all = [apple_reuters[i][j] for i in range(0, len(apple_reuters)) for j in range(0, len(apple_reuters[i]))]\n",
    "apple_article_nbc_news_all = [apple_nbc_news[i][j] for i in range(0, len(apple_nbc_news)) for j in range(0, len(apple_nbc_news[i]))]\n",
    "apple_article_techcrunch_all = [apple_techcrunch[i][j] for i in range(0, len(apple_techcrunch)) for j in range(0, len(apple_techcrunch[i]))]\n",
    "apple_article_nyt_all = [apple_nyt[i][j] for i in range(0, len(apple_nyt)) for j in range(0, len(apple_nyt[i]))]\n",
    "apple_article_wired_all = [apple_wired[i][j] for i in range(0, len(apple_wired)) for j in range(0, len(apple_wired[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert news onjects to the dataframe - apple\n",
    "apple_article_abc_df = (pd.DataFrame(apple_article_abc_all)).drop_duplicates(subset = 'title').reset_index(drop = True)\n",
    "apple_article_business_insider_df = (pd.DataFrame(apple_article_business_insider_all)).drop_duplicates(subset = 'title').reset_index(drop = True)\n",
    "apple_article_reuters_df = (pd.DataFrame(apple_article_reuters_all)).drop_duplicates(subset = 'title').reset_index(drop = True)\n",
    "apple_article_nbc_news_df = (pd.DataFrame(apple_article_nbc_news_all)).drop_duplicates(subset = 'title').reset_index(drop = True)\n",
    "apple_article_techcrunch_df = (pd.DataFrame(apple_article_techcrunch_all)).drop_duplicates(subset = 'title').reset_index(drop = True)\n",
    "apple_article_nyt_df = (pd.DataFrame(apple_article_nyt_all)).drop_duplicates(subset = 'title').reset_index(drop = True)\n",
    "apple_article_wired_df = (pd.DataFrame(apple_article_wired_all)).drop_duplicates(subset = 'title').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple buys startup focused on lenses for AR gl...\n",
       "1     Apple buys startup focussed on lenses for AR g...\n",
       "2     White House probes Google after Trump accuses ...\n",
       "3     Trump accuses Google of hiding 'fair media' co...\n",
       "4     Trump accuses Google of hiding 'fair media' co...\n",
       "5                     EU mergers and takeovers (Aug 28)\n",
       "6     Williams gets warm welcome and win in U.S. Ope...\n",
       "7     China clamping down on transport sector after ...\n",
       "8     China clamping down on transport sector after ...\n",
       "9     U.S. Open celebrates 50th birthday with $600 m...\n",
       "10    Tennis: U.S. Open celebrates 50th birthday wit...\n",
       "11    UPDATE 1-Twitter CEO to testify before U.S. Ho...\n",
       "12    Twitter CEO Dorsey to testify before House pan...\n",
       "13    As big firms get bigger, rate cuts may pack le...\n",
       "14    Trump accuses social media firms of 'silencing...\n",
       "15    'Old' bull market sputters on while tech inflo...\n",
       "16                    EU mergers and takeovers (Aug 24)\n",
       "17    Trump slams social media firms as 'silencing m...\n",
       "18    Trump slams social media firms for 'silencing ...\n",
       "19    U.S. CEOs warn of harm from Trump administrati...\n",
       "20                    EU mergers and takeovers (Aug 23)\n",
       "21    Panasonic joins effort to license out low-cost...\n",
       "22        UPDATE 1-UK Stocks-Factors to watch on Aug 23\n",
       "23                 UK Stocks-Factors to watch on Aug 23\n",
       "24          PRESS DIGEST - Wall Street Journal - Aug 23\n",
       "25    Wall Street's sector shakeup will let more tec...\n",
       "26    Analysis: Wall Street's sector shakeup will le...\n",
       "27    Apple to gain unconditional EU approval for Sh...\n",
       "28                    EU mergers and takeovers (Aug 22)\n",
       "29    EU set to clear Apple's bid for music app Shaz...\n",
       "30     S&P 500 bull market now arguably the oldest ever\n",
       "31    UPDATE 2-Apple supplier AAC Tech posts first p...\n",
       "32    China Xiaomi's second-quarter revenue soars 68...\n",
       "33    UPDATE 1-Apple supplier AAC Tech reports rare ...\n",
       "34    iPhone parts supplier AAC reports rare fall in...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_article_reuters_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to update dataframes with the article texts \n",
    "def df_all_articles(articles_df):\n",
    "    articles_df['text'] = np.nan\n",
    "    for i in range(0, len(articles_df)):\n",
    "        html_page = requests.get(articles_df['url'][i]) #Make a get request to retrieve the page\n",
    "        soup = BeautifulSoup(html_page.content, 'html.parser', from_encoding=\"iso-8859-1\")\n",
    "        article = soup.findAll('p')\n",
    "        str_list = []\n",
    "        list_ = []\n",
    "        for j in range(0,len(article)):\n",
    "            clean = article[j].text\n",
    "            str_list.append(clean)\n",
    "        article_ = ' '.join(str_list)\n",
    "        articles_df['text'][i] = article_\n",
    "    return articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "apple_abc_all_df = df_all_articles(apple_article_abc_df)\n",
    "apple_business_insider_all_df = df_all_articles(apple_article_business_insider_df)\n",
    "apple_reuters_all_df = df_all_articles(apple_article_reuters_df)\n",
    "apple_nbc_news_all_df = df_all_articles(apple_article_nbc_news_df)\n",
    "apple_techcrunch_all_df = df_all_articles(apple_article_techcrunch_df)\n",
    "apple_nyt_all_df = df_all_articles(apple_article_nyt_df)\n",
    "apple_wired_all_df = df_all_articles(apple_article_wired_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the dateframes - apple\n",
    "master_df = apple_abc_all_df.append([apple_business_insider_all_df, apple_reuters_all_df, apple_nbc_news_all_df, apple_techcrunch_all_df, apple_nyt_all_df, apple_article_wired_df]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the df by the number of company names in the apple (>=2)\n",
    "master_df = master_df[master_df['text'].str.split().apply(lambda x: x.count('Facebook'))>=2].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/naokosuga/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def df_with_polarity_score(art_df):\n",
    "    art_df['neg'] = np.nan\n",
    "    art_df['neu'] = np.nan\n",
    "    art_df['pos'] = np.nan\n",
    "    art_df['compound'] = np.nan\n",
    "    art_df = art_df.reset_index(drop=True)\n",
    "    for i in range(0, len(art_df)):\n",
    "        scores = sid.polarity_scores(art_df['text'][i])\n",
    "        art_df['neg'][i] = scores['neg']\n",
    "        art_df['neu'][i] = scores['neu']\n",
    "        art_df['pos'][i] = scores['pos']\n",
    "        art_df['compound'][i] = scores['compound']\n",
    "    return art_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "master_df_with_polarity = df_with_polarity_score(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the publishedAt and change the dtype to datetime\n",
    "master_df_with_polarity['publishedAt'] = master_df_with_polarity['publishedAt'].str.replace('T', \" \").str.replace(\"Z\", \"\")\n",
    "master_df_with_polarity['publishedAt'] = pd.to_datetime(master_df_with_polarity['publishedAt'])\n",
    "# clean up source column\n",
    "master_df_with_polarity['source'] = master_df_with_polarity['source'].apply(lambda x: x['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index column\n",
    "apple_articles_df = master_df_with_polarity.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv\n",
    "apple_articles_df.to_csv('apple_articles_20180822_20180829_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
