{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv('netflix_article_avgs.csv', index_col = 0)\n",
    "articles_df.index = pd.to_datetime(articles_df.index)\n",
    "articles_df_ = articles_df[articles_df.index.day >= 24]\n",
    "articles_df = articles_df_[articles_df_.index.day < 30]\n",
    "articles_df = articles_df.between_time('9:30', \"15:30\").sort_index()\n",
    "\n",
    "# importing tweet csv files and cleaning them\n",
    "tweets_df = pd.read_csv('netflix_tweets.csv')\n",
    "tweets_df['time_stamp'] = pd.to_datetime(tweets_df['time_stamp'])\n",
    "tweets_df['time_stamp'] = tweets_df['time_stamp'].dt.round('30min')\n",
    "tweets_df_ = tweets_df.set_index(['time_stamp'])\n",
    "\n",
    "# reading stock.csv and cleaning the df\n",
    "running_stocks_thirty = pd.read_csv('netflix_stock_8_30.csv', index_col = 0)\n",
    "running_stocks_thirty.index = pd.to_datetime(running_stocks_thirty.index)\n",
    "\n",
    "# updating stock data\n",
    "running_stocks_thirty = running_stocks_thirty[running_stocks_thirty.index.day >= 24].sort_index()\n",
    "running_stocks_thirty['increase_decrease'] = running_stocks_thirty['4. close'] - running_stocks_thirty['1. open']\n",
    "running_stocks_thirty['up_down'] = np.where(running_stocks_thirty['increase_decrease']>=0, 1, 0)\n",
    "running_stocks_thirty['movement(%)'] = np.round(((running_stocks_thirty['4. close'] - running_stocks_thirty['1. open'])/running_stocks_thirty['4. close'])*100, 2)\n",
    "\n",
    "# reading tech indicators\n",
    "tech_indic = pd.read_csv('netflix_tech_indicators.csv', index_col = 0 )\n",
    "tech_indic.index = pd.to_datetime(tech_indic.index)\n",
    "tech_indic_ = tech_indic[tech_indic.index.day >= 24]\n",
    "tech_indic_df = tech_indic_[tech_indic_.index.day < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the tweets before the 24th\n",
    "tweets_df = tweets_df_[tweets_df_.index.day >= 24]\n",
    "tweets_master_df = tweets_df.drop(['t_id', 'text', 'Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate during/after market hrs\n",
    "def during_after(df):\n",
    "    df_during = df.between_time('9:30', \"15:30\")\n",
    "    df_after = df.between_time('15:30', \"9:30\")\n",
    "    return df_during, df_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_24, after_hour_tweets_24 = during_after(tweets_df_24)\n",
    "open_hours_tweets_25, after_hour_tweets_25 = during_after(tweets_df_25)\n",
    "open_hours_tweets_26, after_hour_tweets_26 = during_after(tweets_df_26)\n",
    "open_hours_tweets_27, after_hour_tweets_27 = during_after(tweets_df_27)\n",
    "open_hours_tweets_28, after_hour_tweets_28 = during_after(tweets_df_28)\n",
    "open_hours_tweets_29, after_hour_tweets_29 = during_after(tweets_df_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the scores \n",
    "def aggregate(df):\n",
    "    if df.empty != True:\n",
    "        sent_avg = df.groupby(df.index).agg({'vader_sentiment': 'mean'}).rename(columns = {'vader_sentiment': 'sentiment_avg_30'}).shift()\n",
    "        sent_count = df.groupby(df.index).agg({'sentiment': 'value_counts'}).unstack().rename(columns = {'sentiment': 'sentiment_30'}).shift()\n",
    "        df_ = pd.concat([sent_avg, sent_count], axis = 1)\n",
    "        df_ini = df_.fillna(df_.mean())\n",
    "        df_hour_i = df_ini.shift().rolling(window=2, center = True, min_periods=2).mean().rename(columns = {'sentiment_avg_30': 'sentiment_avg_60'})\n",
    "        df_hour = df_hour_i.fillna(df_hour_i.mean())\n",
    "        df_two_hours_i = df_ini.shift(2).rolling(window=4, center = True, min_periods=4).mean().rename(columns = {'sentiment_avg_30': 'sentiment_avg_120'})\n",
    "        df_two_hours = df_two_hours_i.fillna(df_two_hours_i.mean())\n",
    "        df_all = pd.concat([df_ini, df_hour, df_two_hours], axis = 1)\n",
    "        return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_24 = aggregate(open_hours_tweets_24)\n",
    "open_hours_tweets_25 = aggregate(open_hours_tweets_25)\n",
    "open_hours_tweets_26 = aggregate(open_hours_tweets_26)\n",
    "open_hours_tweets_27 = aggregate(open_hours_tweets_27)\n",
    "open_hours_tweets_28 = aggregate(open_hours_tweets_28)\n",
    "open_hours_tweets_29 = aggregate(open_hours_tweets_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morning = tweets_23_night.between_time('0:00', \"9:30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate night-before and morning-day-of market hrs\n",
    "def night_morning(df):\n",
    "    df_night = df.between_time('15:30', \"0:00\")\n",
    "    df_morning = df.between_time('0:00', \"9:30\")\n",
    "    df_night_avg = df_night.groupby(df_night.index.day).mean()\n",
    "    df_night_ct = df_night.groupby(df_night.index.day).agg({'sentiment': 'value_counts'}).unstack()\n",
    "    night_df = pd.concat([df_night_avg, df_night_ct], axis = 1)\n",
    "    if df_morning.empty != True:\n",
    "        df_morning_avg = df_morning.groupby(df_morning.index.day).mean()\n",
    "        df_morning_ct = df_morning.groupby(df_morning.index.day).agg({'sentiment': 'value_counts'}).unstack()\n",
    "        morning_df = pd.concat([df_morning_avg, df_morning_ct], axis = 1)\n",
    "    else:\n",
    "        morning_df = df_morning\n",
    "    if len(night_df.columns) == 4:\n",
    "        night_df.columns = ['vader_sentiment_night', 'sent_neg, night_before', 'sent_neu, night_before', 'sent_pos, night_before']\n",
    "    if len(morning_df.columns) == 4:\n",
    "        morning_df.columns = ['vader_sentiment_morning', 'sent_neg, morning', 'sent_neu, morning', 'sent_pos, morning']\n",
    "    pd.to_datetime(morning_df.index)\n",
    "    pd.to_datetime(night_df.index)\n",
    "    return night_df, morning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_23 = tweets_df_[tweets_df_.index.day == 23]\n",
    "tweets_23_df = tweets_df_23.drop(['t_id', 'text', 'Unnamed: 0'], axis = 1)\n",
    "tweets_23_night = tweets_23_df.between_time('15:30', \"9:30\")\n",
    "after_hour_tweets_24_night, after_hour_tweets_23_morning = night_morning(tweets_23_night)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_hour_tweets_25_night, after_hour_tweets_24_morning = night_morning(after_hour_tweets_24)\n",
    "after_hour_tweets_26_night, after_hour_tweets_25_morning = night_morning(after_hour_tweets_25)\n",
    "after_hour_tweets_27_night, after_hour_tweets_26_morning = night_morning(after_hour_tweets_26)\n",
    "after_hour_tweets_28_night, after_hour_tweets_27_morning = night_morning(after_hour_tweets_27)\n",
    "after_hour_tweets_29_night, after_hour_tweets_28_morning = night_morning(after_hour_tweets_28)\n",
    "after_hour_tweets_30_night, after_hour_tweets_29_morning = night_morning(after_hour_tweets_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the index of the night df to the next day\n",
    "after_hour_tweets_24_night.index = [24]\n",
    "after_hour_tweets_25_night.index = [25]\n",
    "after_hour_tweets_26_night.index = [26]\n",
    "after_hour_tweets_27_night.index = [27]\n",
    "after_hour_tweets_28_night.index = [28]\n",
    "after_hour_tweets_29_night.index = [29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_morning_24 = pd.concat([after_hour_tweets_24_night, after_hour_tweets_24_morning], axis = 1)\n",
    "night_morning_25 = pd.concat([after_hour_tweets_25_night, after_hour_tweets_25_morning], axis = 1)\n",
    "night_morning_26 = pd.concat([after_hour_tweets_26_night, after_hour_tweets_26_morning], axis = 1)\n",
    "night_morning_27 = pd.concat([after_hour_tweets_27_night, after_hour_tweets_27_morning], axis = 1)\n",
    "night_morning_28 = pd.concat([after_hour_tweets_28_night, after_hour_tweets_28_morning], axis = 1)\n",
    "night_morning_29 = pd.concat([after_hour_tweets_29_night, after_hour_tweets_29_morning], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = list(night_morning_24.columns)\n",
    "def concat_main_night_morning(open_hour_df, night_morning_df):\n",
    "    for i in range(0,len(list_of_columns)):\n",
    "        open_hour_df[list_of_columns[i]] = np.full((len(open_hour_df),1), night_morning_df[list_of_columns[i]].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_24 = open_hours_tweets_25.copy()\n",
    "open_hours_tweets_27 = open_hours_tweets_25.copy()\n",
    "open_hours_tweets_28 = open_hours_tweets_25.copy()\n",
    "open_hours_tweets_29 = open_hours_tweets_25.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_avg_30</th>\n",
       "      <th>(sentiment_30, neg)</th>\n",
       "      <th>(sentiment_30, neutral)</th>\n",
       "      <th>(sentiment_30, pos)</th>\n",
       "      <th>sentiment_avg_60</th>\n",
       "      <th>(sentiment_30, neg)</th>\n",
       "      <th>(sentiment_30, neutral)</th>\n",
       "      <th>(sentiment_30, pos)</th>\n",
       "      <th>sentiment_avg_120</th>\n",
       "      <th>(sentiment_30, neg)</th>\n",
       "      <th>(sentiment_30, neutral)</th>\n",
       "      <th>(sentiment_30, pos)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_stamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-25 14:30:00</th>\n",
       "      <td>0.154259</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.141695</td>\n",
       "      <td>18.5</td>\n",
       "      <td>31.75</td>\n",
       "      <td>37.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-25 15:00:00</th>\n",
       "      <td>0.129131</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.141695</td>\n",
       "      <td>18.5</td>\n",
       "      <td>31.75</td>\n",
       "      <td>37.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-25 15:30:00</th>\n",
       "      <td>0.179387</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.141695</td>\n",
       "      <td>18.5</td>\n",
       "      <td>31.75</td>\n",
       "      <td>37.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sentiment_avg_30  (sentiment_30, neg)  \\\n",
       "time_stamp                                                   \n",
       "2018-08-25 14:30:00          0.154259                 20.0   \n",
       "2018-08-25 15:00:00          0.129131                 17.0   \n",
       "2018-08-25 15:30:00          0.179387                 23.0   \n",
       "\n",
       "                     (sentiment_30, neutral)  (sentiment_30, pos)  \\\n",
       "time_stamp                                                          \n",
       "2018-08-25 14:30:00                     37.5                 43.5   \n",
       "2018-08-25 15:00:00                     26.0                 31.0   \n",
       "2018-08-25 15:30:00                     49.0                 56.0   \n",
       "\n",
       "                     sentiment_avg_60  (sentiment_30, neg)  \\\n",
       "time_stamp                                                   \n",
       "2018-08-25 14:30:00          0.141695                 18.5   \n",
       "2018-08-25 15:00:00          0.141695                 18.5   \n",
       "2018-08-25 15:30:00          0.141695                 18.5   \n",
       "\n",
       "                     (sentiment_30, neutral)  (sentiment_30, pos)  \\\n",
       "time_stamp                                                          \n",
       "2018-08-25 14:30:00                    31.75                37.25   \n",
       "2018-08-25 15:00:00                    31.75                37.25   \n",
       "2018-08-25 15:30:00                    31.75                37.25   \n",
       "\n",
       "                     sentiment_avg_120  (sentiment_30, neg)  \\\n",
       "time_stamp                                                    \n",
       "2018-08-25 14:30:00                NaN                  NaN   \n",
       "2018-08-25 15:00:00                NaN                  NaN   \n",
       "2018-08-25 15:30:00                NaN                  NaN   \n",
       "\n",
       "                     (sentiment_30, neutral)  (sentiment_30, pos)  \n",
       "time_stamp                                                         \n",
       "2018-08-25 14:30:00                      NaN                  NaN  \n",
       "2018-08-25 15:00:00                      NaN                  NaN  \n",
       "2018-08-25 15:30:00                      NaN                  NaN  "
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_hours_tweets_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_main_night_morning(open_hours_tweets_24, night_morning_24) # replace later\n",
    "concat_main_night_morning(open_hours_tweets_25, night_morning_25)\n",
    "concat_main_night_morning(open_hours_tweets_26, night_morning_26)\n",
    "concat_main_night_morning(open_hours_tweets_27, night_morning_27)\n",
    "concat_main_night_morning(open_hours_tweets_28, night_morning_28)\n",
    "concat_main_night_morning(open_hours_tweets_29, night_morning_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_24.columns = ['sentiment_avg_30','coun_neg, 30', 'coun_neu, 30','coun_pos, 30', 'sentiment_avg_60', 'coun_neg, 60', 'coun_neu, 60','coun_pos, 60','sentiment_avg_120', 'coun_neg, 120', 'coun_neu, 120','coun_pos, 120', 'sentiment_night_before_avg', 'count_neg, night_before', 'count_neu, night_before', 'count_pos, night_before','sentiment_morning_avg', 'count_neg, morning', 'count_neu, morning', 'count_pos, morning']\n",
    "open_hours_tweets_27.columns = ['sentiment_avg_30','coun_neg, 30', 'coun_neu, 30','coun_pos, 30', 'sentiment_avg_60', 'coun_neg, 60', 'coun_neu, 60','coun_pos, 60','sentiment_avg_120', 'coun_neg, 120', 'coun_neu, 120','coun_pos, 120', 'sentiment_night_before_avg', 'count_neg, night_before', 'count_neu, night_before', 'count_pos, night_before','sentiment_morning_avg', 'count_neg, morning', 'count_neu, morning', 'count_pos, morning']\n",
    "open_hours_tweets_28.columns = ['sentiment_avg_30','coun_neg, 30', 'coun_neu, 30','coun_pos, 30', 'sentiment_avg_60', 'coun_neg, 60', 'coun_neu, 60','coun_pos, 60','sentiment_avg_120', 'coun_neg, 120', 'coun_neu, 120','coun_pos, 120', 'sentiment_night_before_avg', 'count_neg, night_before', 'count_neu, night_before', 'count_pos, night_before','sentiment_morning_avg', 'count_neg, morning', 'count_neu, morning', 'count_pos, morning']\n",
    "open_hours_tweets_29.columns = ['sentiment_avg_30','coun_neg, 30', 'coun_neu, 30','coun_pos, 30', 'sentiment_avg_60', 'coun_neg, 60', 'coun_neu, 60','coun_pos, 60','sentiment_avg_120', 'coun_neg, 120', 'coun_neu, 120','coun_pos, 120', 'sentiment_night_before_avg', 'count_neg, night_before', 'count_neu, night_before', 'count_pos, night_before','sentiment_morning_avg', 'count_neg, morning', 'count_neu, morning', 'count_pos, morning']\n",
    "open_hours_tweets_25.columns = ['sentiment_avg_30','coun_neg, 30', 'coun_neu, 30','coun_pos, 30', 'sentiment_avg_60', 'coun_neg, 60', 'coun_neu, 60','coun_pos, 60','sentiment_avg_120', 'coun_neg, 120', 'coun_neu, 120','coun_pos, 120', 'sentiment_night_before_avg', 'count_neg, night_before', 'count_neu, night_before', 'count_pos, night_before','sentiment_morning_avg', 'count_neg, morning', 'count_neu, morning', 'count_pos, morning']\n",
    "open_hours_tweets_26.columns = ['sentiment_avg_30','coun_neg, 30', 'coun_neu, 30','coun_pos, 30', 'sentiment_avg_60', 'coun_neg, 60', 'coun_neu, 60','coun_pos, 60','sentiment_avg_120', 'coun_neg, 120', 'coun_neu, 120','coun_pos, 120', 'sentiment_night_before_avg', 'count_neg, night_before', 'count_neu, night_before', 'count_pos, night_before','sentiment_morning_avg', 'count_neg, morning', 'count_neu, morning', 'count_pos, morning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_24['sentiment_avg_30'] = 0\n",
    "open_hours_tweets_24['coun_neg, 30'] = 0\n",
    "open_hours_tweets_24['coun_neu, 30'] = 0\n",
    "open_hours_tweets_24['coun_pos, 30'] = 0\n",
    "open_hours_tweets_24['sentiment_avg_60'] = 0\n",
    "open_hours_tweets_24['coun_neg, 60'] = 0\n",
    "open_hours_tweets_24['coun_neu, 60'] = 0\n",
    "open_hours_tweets_24['coun_pos, 60'] = 0\n",
    "open_hours_tweets_24['sentiment_avg_120'] = 0\n",
    "open_hours_tweets_24['coun_neg, 120'] = 0\n",
    "open_hours_tweets_24['coun_neu, 120'] = 0\n",
    "open_hours_tweets_24['coun_pos, 120'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_27['sentiment_avg_30'] = 0\n",
    "open_hours_tweets_27['coun_neg, 30'] = 0\n",
    "open_hours_tweets_27['coun_neu, 30'] = 0\n",
    "open_hours_tweets_27['coun_pos, 30'] = 0\n",
    "open_hours_tweets_27['sentiment_avg_60'] = 0\n",
    "open_hours_tweets_27['coun_neg, 60'] = 0\n",
    "open_hours_tweets_27['coun_neu, 60'] = 0\n",
    "open_hours_tweets_27['coun_pos, 60'] = 0\n",
    "open_hours_tweets_27['sentiment_avg_120'] = 0\n",
    "open_hours_tweets_27['coun_neg, 120'] = 0\n",
    "open_hours_tweets_27['coun_neu, 120'] = 0\n",
    "open_hours_tweets_27['coun_pos, 120'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_28['sentiment_avg_30'] = 0\n",
    "open_hours_tweets_28['coun_neg, 30'] = 0\n",
    "open_hours_tweets_28['coun_neu, 30'] = 0\n",
    "open_hours_tweets_28['coun_pos, 30'] = 0\n",
    "open_hours_tweets_28['sentiment_avg_60'] = 0\n",
    "open_hours_tweets_28['coun_neg, 60'] = 0\n",
    "open_hours_tweets_28['coun_neu, 60'] = 0\n",
    "open_hours_tweets_28['coun_pos, 60'] = 0\n",
    "open_hours_tweets_28['sentiment_avg_120'] = 0\n",
    "open_hours_tweets_28['coun_neg, 120'] = 0\n",
    "open_hours_tweets_28['coun_neu, 120'] = 0\n",
    "open_hours_tweets_28['coun_pos, 120'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_29['sentiment_avg_30'] = 0\n",
    "open_hours_tweets_29['coun_neg, 30'] = 0\n",
    "open_hours_tweets_29['coun_neu, 30'] = 0\n",
    "open_hours_tweets_29['coun_pos, 30'] = 0\n",
    "open_hours_tweets_29['sentiment_avg_60'] = 0\n",
    "open_hours_tweets_29['coun_neg, 60'] = 0\n",
    "open_hours_tweets_29['coun_neu, 60'] = 0\n",
    "open_hours_tweets_29['coun_pos, 60'] = 0\n",
    "open_hours_tweets_29['sentiment_avg_120'] = 0\n",
    "open_hours_tweets_29['coun_neg, 120'] = 0\n",
    "open_hours_tweets_29['coun_neu, 120'] = 0\n",
    "open_hours_tweets_29['coun_pos, 120'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hours_tweets_24_col = pd.DataFrame(pd.DatetimeIndex(['2018-08-24 14:30:00', '2018-08-24 15:00:00',\n",
    "               '2018-08-24 15:30:00']))\n",
    "open_hours_tweets_24_col.columns = ['time_stamp']\n",
    "open_hours_tweets_24_col = open_hours_tweets_24_col.set_index(['time_stamp'])\n",
    "open_hours_tweets_24.index = open_hours_tweets_24_col.index\n",
    "open_hours_tweets_27_col = pd.DataFrame(pd.DatetimeIndex(['2018-08-27 14:30:00', '2018-08-27 15:00:00',\n",
    "               '2018-08-27 15:30:00']))\n",
    "open_hours_tweets_27_col.columns = ['time_stamp']\n",
    "open_hours_tweets_27_col = open_hours_tweets_27_col.set_index(['time_stamp'])\n",
    "open_hours_tweets_27.index = open_hours_tweets_27_col.index\n",
    "open_hours_tweets_28_col = pd.DataFrame(pd.DatetimeIndex(['2018-08-28 14:30:00', '2018-08-28 15:00:00',\n",
    "               '2018-08-28 15:30:00']))\n",
    "open_hours_tweets_28_col.columns = ['time_stamp']\n",
    "open_hours_tweets_28_col = open_hours_tweets_28_col.set_index(['time_stamp'])\n",
    "open_hours_tweets_28.index = open_hours_tweets_28_col.index\n",
    "open_hours_tweets_29_col = pd.DataFrame(pd.DatetimeIndex(['2018-08-29 14:30:00', '2018-08-29 15:00:00',\n",
    "               '2018-08-29 15:30:00']))\n",
    "open_hours_tweets_29_col.columns = ['time_stamp']\n",
    "open_hours_tweets_29_col = open_hours_tweets_29_col.set_index(['time_stamp'])\n",
    "open_hours_tweets_29.index = open_hours_tweets_29_col.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_avg_30</th>\n",
       "      <th>coun_neg, 30</th>\n",
       "      <th>coun_neu, 30</th>\n",
       "      <th>coun_pos, 30</th>\n",
       "      <th>sentiment_avg_60</th>\n",
       "      <th>coun_neg, 60</th>\n",
       "      <th>coun_neu, 60</th>\n",
       "      <th>coun_pos, 60</th>\n",
       "      <th>sentiment_avg_120</th>\n",
       "      <th>coun_neg, 120</th>\n",
       "      <th>coun_neu, 120</th>\n",
       "      <th>coun_pos, 120</th>\n",
       "      <th>sentiment_night_before_avg</th>\n",
       "      <th>count_neg, night_before</th>\n",
       "      <th>count_neu, night_before</th>\n",
       "      <th>count_pos, night_before</th>\n",
       "      <th>sentiment_morning_avg</th>\n",
       "      <th>count_neg, morning</th>\n",
       "      <th>count_neu, morning</th>\n",
       "      <th>count_pos, morning</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_stamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-26 14:30:00</th>\n",
       "      <td>0.193185</td>\n",
       "      <td>19.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.214078</td>\n",
       "      <td>16.5</td>\n",
       "      <td>41.75</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214493</td>\n",
       "      <td>434</td>\n",
       "      <td>825</td>\n",
       "      <td>1403</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-26 15:00:00</th>\n",
       "      <td>0.234971</td>\n",
       "      <td>14.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.214078</td>\n",
       "      <td>16.5</td>\n",
       "      <td>41.75</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214493</td>\n",
       "      <td>434</td>\n",
       "      <td>825</td>\n",
       "      <td>1403</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-26 15:30:00</th>\n",
       "      <td>0.151400</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.214078</td>\n",
       "      <td>16.5</td>\n",
       "      <td>41.75</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214493</td>\n",
       "      <td>434</td>\n",
       "      <td>825</td>\n",
       "      <td>1403</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sentiment_avg_30  coun_neg, 30  coun_neu, 30  \\\n",
       "time_stamp                                                          \n",
       "2018-08-26 14:30:00          0.193185          19.0          39.5   \n",
       "2018-08-26 15:00:00          0.234971          14.0          44.0   \n",
       "2018-08-26 15:30:00          0.151400          24.0          35.0   \n",
       "\n",
       "                     coun_pos, 30  sentiment_avg_60  coun_neg, 60  \\\n",
       "time_stamp                                                          \n",
       "2018-08-26 14:30:00          55.0          0.214078          16.5   \n",
       "2018-08-26 15:00:00          59.0          0.214078          16.5   \n",
       "2018-08-26 15:30:00          51.0          0.214078          16.5   \n",
       "\n",
       "                     coun_neu, 60  coun_pos, 60  sentiment_avg_120  \\\n",
       "time_stamp                                                           \n",
       "2018-08-26 14:30:00         41.75          57.0                NaN   \n",
       "2018-08-26 15:00:00         41.75          57.0                NaN   \n",
       "2018-08-26 15:30:00         41.75          57.0                NaN   \n",
       "\n",
       "                     coun_neg, 120  coun_neu, 120  coun_pos, 120  \\\n",
       "time_stamp                                                         \n",
       "2018-08-26 14:30:00            NaN            NaN            NaN   \n",
       "2018-08-26 15:00:00            NaN            NaN            NaN   \n",
       "2018-08-26 15:30:00            NaN            NaN            NaN   \n",
       "\n",
       "                     sentiment_night_before_avg  count_neg, night_before  \\\n",
       "time_stamp                                                                 \n",
       "2018-08-26 14:30:00                    0.214493                      434   \n",
       "2018-08-26 15:00:00                    0.214493                      434   \n",
       "2018-08-26 15:30:00                    0.214493                      434   \n",
       "\n",
       "                     count_neu, night_before  count_pos, night_before  \\\n",
       "time_stamp                                                              \n",
       "2018-08-26 14:30:00                      825                     1403   \n",
       "2018-08-26 15:00:00                      825                     1403   \n",
       "2018-08-26 15:30:00                      825                     1403   \n",
       "\n",
       "                     sentiment_morning_avg  count_neg, morning  \\\n",
       "time_stamp                                                       \n",
       "2018-08-26 14:30:00               0.049713                  19   \n",
       "2018-08-26 15:00:00               0.049713                  19   \n",
       "2018-08-26 15:30:00               0.049713                  19   \n",
       "\n",
       "                     count_neu, morning  count_pos, morning  \n",
       "time_stamp                                                   \n",
       "2018-08-26 14:30:00                  19                  30  \n",
       "2018-08-26 15:00:00                  19                  30  \n",
       "2018-08-26 15:30:00                  19                  30  "
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_hours_tweets_26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_master = pd.concat([open_hours_tweets_24, open_hours_tweets_25, open_hours_tweets_26, open_hours_tweets_27, open_hours_tweets_28, open_hours_tweets_29])\n",
    "# tweets_master.columns = ['sentiment_avg_30','coun_neg, 30', 'coun_neu, 30','coun_pos, 30', 'sentiment_avg_60', 'coun_neg, 60', 'coun_neu, 60','coun_pos, 60','sentiment_avg_120', 'coun_neg, 120', 'coun_neu, 120','coun_pos, 120', 'sentiment_night_before_avg', 'count_neg, night_before', 'count_neu, night_before', 'count_pos, night_before','sentiment_morning_avg', 'count_neg, morning', 'count_neu, morning', 'count_pos, morning']\n",
    "# take out weekend\n",
    "tweets_master = tweets_master[(tweets_master.index.day != 25) & (tweets_master.index.day != 26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = articles_df.index\n",
    "tweets_master = tweets_master.reindex(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.time(9, 30), datetime.time(9, 30), datetime.time(10, 0),\n",
       "       datetime.time(10, 0), datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(11, 0), datetime.time(11, 0), datetime.time(11, 30),\n",
       "       datetime.time(11, 30), datetime.time(12, 0), datetime.time(12, 0),\n",
       "       datetime.time(12, 30), datetime.time(12, 30), datetime.time(13, 0),\n",
       "       datetime.time(13, 0), datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(14, 0), datetime.time(14, 0), datetime.time(14, 30),\n",
       "       datetime.time(14, 30), datetime.time(15, 0), datetime.time(15, 0),\n",
       "       datetime.time(15, 30), datetime.time(15, 30), datetime.time(9, 30),\n",
       "       datetime.time(9, 30), datetime.time(10, 0), datetime.time(10, 0),\n",
       "       datetime.time(10, 30), datetime.time(10, 30), datetime.time(11, 0),\n",
       "       datetime.time(11, 0), datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(12, 0), datetime.time(12, 0), datetime.time(12, 30),\n",
       "       datetime.time(12, 30), datetime.time(13, 0), datetime.time(13, 0),\n",
       "       datetime.time(13, 30), datetime.time(13, 30), datetime.time(14, 0),\n",
       "       datetime.time(14, 0), datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(15, 0), datetime.time(15, 0), datetime.time(15, 30),\n",
       "       datetime.time(15, 30), datetime.time(9, 30), datetime.time(9, 30),\n",
       "       datetime.time(10, 0), datetime.time(10, 0), datetime.time(10, 0),\n",
       "       datetime.time(10, 15), datetime.time(10, 15),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 45), datetime.time(10, 45), datetime.time(11, 0),\n",
       "       datetime.time(11, 0), datetime.time(11, 0), datetime.time(11, 0),\n",
       "       datetime.time(11, 15), datetime.time(11, 15),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 45), datetime.time(11, 45), datetime.time(12, 0),\n",
       "       datetime.time(12, 0), datetime.time(12, 0), datetime.time(12, 0),\n",
       "       datetime.time(12, 15), datetime.time(12, 15),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 45), datetime.time(12, 45), datetime.time(13, 0),\n",
       "       datetime.time(13, 0), datetime.time(13, 0), datetime.time(13, 0),\n",
       "       datetime.time(13, 15), datetime.time(13, 15),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 45), datetime.time(13, 45), datetime.time(14, 0),\n",
       "       datetime.time(14, 0), datetime.time(14, 0), datetime.time(14, 0),\n",
       "       datetime.time(14, 15), datetime.time(14, 15),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 45), datetime.time(14, 45), datetime.time(15, 0),\n",
       "       datetime.time(15, 0), datetime.time(15, 0), datetime.time(15, 0),\n",
       "       datetime.time(15, 15), datetime.time(15, 15),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 45), datetime.time(15, 45), datetime.time(9, 30),\n",
       "       datetime.time(9, 30), datetime.time(9, 30), datetime.time(9, 30),\n",
       "       datetime.time(9, 45), datetime.time(9, 45), datetime.time(10, 0),\n",
       "       datetime.time(10, 0), datetime.time(10, 0), datetime.time(10, 0),\n",
       "       datetime.time(10, 15), datetime.time(10, 15),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 45), datetime.time(10, 45), datetime.time(11, 0),\n",
       "       datetime.time(11, 0), datetime.time(11, 0), datetime.time(11, 0),\n",
       "       datetime.time(11, 15), datetime.time(11, 15),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 45), datetime.time(11, 45), datetime.time(12, 0),\n",
       "       datetime.time(12, 0), datetime.time(12, 0), datetime.time(12, 0),\n",
       "       datetime.time(12, 15), datetime.time(12, 15),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 45), datetime.time(12, 45), datetime.time(13, 0),\n",
       "       datetime.time(13, 0), datetime.time(13, 0), datetime.time(13, 0),\n",
       "       datetime.time(13, 15), datetime.time(13, 15),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 45), datetime.time(13, 45), datetime.time(14, 0),\n",
       "       datetime.time(14, 0), datetime.time(14, 0), datetime.time(14, 0),\n",
       "       datetime.time(14, 15), datetime.time(14, 15),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 45), datetime.time(14, 45), datetime.time(15, 0),\n",
       "       datetime.time(15, 0), datetime.time(15, 0), datetime.time(15, 0),\n",
       "       datetime.time(15, 15), datetime.time(15, 15),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 45), datetime.time(15, 45), datetime.time(9, 30),\n",
       "       datetime.time(9, 30), datetime.time(9, 30), datetime.time(9, 30),\n",
       "       datetime.time(9, 45), datetime.time(9, 45), datetime.time(10, 0),\n",
       "       datetime.time(10, 0), datetime.time(10, 0), datetime.time(10, 0),\n",
       "       datetime.time(10, 15), datetime.time(10, 15),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 45), datetime.time(10, 45), datetime.time(11, 0),\n",
       "       datetime.time(11, 0), datetime.time(11, 0), datetime.time(11, 0),\n",
       "       datetime.time(11, 15), datetime.time(11, 15),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 45), datetime.time(11, 45), datetime.time(12, 0),\n",
       "       datetime.time(12, 0), datetime.time(12, 0), datetime.time(12, 0),\n",
       "       datetime.time(12, 15), datetime.time(12, 15),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 45), datetime.time(12, 45), datetime.time(13, 0),\n",
       "       datetime.time(13, 0), datetime.time(13, 0), datetime.time(13, 0),\n",
       "       datetime.time(13, 15), datetime.time(13, 15),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 40), datetime.time(13, 45),\n",
       "       datetime.time(13, 45), datetime.time(13, 45),\n",
       "       datetime.time(13, 50), datetime.time(13, 50),\n",
       "       datetime.time(13, 55), datetime.time(13, 55), datetime.time(14, 0),\n",
       "       datetime.time(14, 0), datetime.time(14, 0), datetime.time(14, 0),\n",
       "       datetime.time(14, 0), datetime.time(14, 0), datetime.time(14, 5),\n",
       "       datetime.time(14, 5), datetime.time(14, 10), datetime.time(14, 10),\n",
       "       datetime.time(14, 15), datetime.time(14, 15),\n",
       "       datetime.time(14, 15), datetime.time(14, 15),\n",
       "       datetime.time(14, 20), datetime.time(14, 20),\n",
       "       datetime.time(14, 25), datetime.time(14, 25),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 35), datetime.time(14, 35),\n",
       "       datetime.time(14, 40), datetime.time(14, 40),\n",
       "       datetime.time(14, 45), datetime.time(14, 45),\n",
       "       datetime.time(14, 45), datetime.time(14, 45),\n",
       "       datetime.time(14, 50), datetime.time(14, 50),\n",
       "       datetime.time(14, 55), datetime.time(14, 55), datetime.time(15, 0),\n",
       "       datetime.time(15, 0), datetime.time(15, 0), datetime.time(15, 0),\n",
       "       datetime.time(15, 0), datetime.time(15, 0), datetime.time(15, 5),\n",
       "       datetime.time(15, 5), datetime.time(15, 10), datetime.time(15, 10),\n",
       "       datetime.time(15, 15), datetime.time(15, 15),\n",
       "       datetime.time(15, 15), datetime.time(15, 15),\n",
       "       datetime.time(15, 20), datetime.time(15, 20),\n",
       "       datetime.time(15, 25), datetime.time(15, 25),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 35), datetime.time(15, 35),\n",
       "       datetime.time(15, 40), datetime.time(15, 40),\n",
       "       datetime.time(15, 45), datetime.time(15, 45),\n",
       "       datetime.time(15, 45), datetime.time(15, 45),\n",
       "       datetime.time(15, 50), datetime.time(15, 50),\n",
       "       datetime.time(15, 55), datetime.time(15, 55), datetime.time(9, 30),\n",
       "       datetime.time(9, 30), datetime.time(9, 30), datetime.time(9, 30),\n",
       "       datetime.time(9, 30), datetime.time(9, 30), datetime.time(9, 35),\n",
       "       datetime.time(9, 35), datetime.time(9, 40), datetime.time(9, 40),\n",
       "       datetime.time(9, 45), datetime.time(9, 45), datetime.time(9, 45),\n",
       "       datetime.time(9, 45), datetime.time(9, 50), datetime.time(9, 50),\n",
       "       datetime.time(9, 55), datetime.time(9, 55), datetime.time(10, 0),\n",
       "       datetime.time(10, 0), datetime.time(10, 0), datetime.time(10, 0),\n",
       "       datetime.time(10, 0), datetime.time(10, 0), datetime.time(10, 5),\n",
       "       datetime.time(10, 5), datetime.time(10, 10), datetime.time(10, 10),\n",
       "       datetime.time(10, 15), datetime.time(10, 15),\n",
       "       datetime.time(10, 15), datetime.time(10, 15),\n",
       "       datetime.time(10, 20), datetime.time(10, 20),\n",
       "       datetime.time(10, 25), datetime.time(10, 25),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 30), datetime.time(10, 30),\n",
       "       datetime.time(10, 35), datetime.time(10, 35),\n",
       "       datetime.time(10, 40), datetime.time(10, 40),\n",
       "       datetime.time(10, 45), datetime.time(10, 45),\n",
       "       datetime.time(10, 45), datetime.time(10, 45),\n",
       "       datetime.time(10, 50), datetime.time(10, 50),\n",
       "       datetime.time(10, 55), datetime.time(10, 55), datetime.time(11, 0),\n",
       "       datetime.time(11, 0), datetime.time(11, 0), datetime.time(11, 0),\n",
       "       datetime.time(11, 0), datetime.time(11, 0), datetime.time(11, 5),\n",
       "       datetime.time(11, 5), datetime.time(11, 10), datetime.time(11, 10),\n",
       "       datetime.time(11, 15), datetime.time(11, 15),\n",
       "       datetime.time(11, 15), datetime.time(11, 15),\n",
       "       datetime.time(11, 20), datetime.time(11, 20),\n",
       "       datetime.time(11, 25), datetime.time(11, 25),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 30), datetime.time(11, 30),\n",
       "       datetime.time(11, 35), datetime.time(11, 35),\n",
       "       datetime.time(11, 40), datetime.time(11, 40),\n",
       "       datetime.time(11, 45), datetime.time(11, 45),\n",
       "       datetime.time(11, 45), datetime.time(11, 45),\n",
       "       datetime.time(11, 50), datetime.time(11, 50),\n",
       "       datetime.time(11, 55), datetime.time(11, 55), datetime.time(12, 0),\n",
       "       datetime.time(12, 0), datetime.time(12, 0), datetime.time(12, 0),\n",
       "       datetime.time(12, 0), datetime.time(12, 0), datetime.time(12, 5),\n",
       "       datetime.time(12, 5), datetime.time(12, 10), datetime.time(12, 10),\n",
       "       datetime.time(12, 15), datetime.time(12, 15),\n",
       "       datetime.time(12, 15), datetime.time(12, 15),\n",
       "       datetime.time(12, 20), datetime.time(12, 20),\n",
       "       datetime.time(12, 25), datetime.time(12, 25),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 30), datetime.time(12, 30),\n",
       "       datetime.time(12, 35), datetime.time(12, 35),\n",
       "       datetime.time(12, 40), datetime.time(12, 40),\n",
       "       datetime.time(12, 45), datetime.time(12, 45),\n",
       "       datetime.time(12, 45), datetime.time(12, 45),\n",
       "       datetime.time(12, 50), datetime.time(12, 50),\n",
       "       datetime.time(12, 55), datetime.time(12, 55), datetime.time(13, 0),\n",
       "       datetime.time(13, 0), datetime.time(13, 0), datetime.time(13, 0),\n",
       "       datetime.time(13, 0), datetime.time(13, 0), datetime.time(13, 5),\n",
       "       datetime.time(13, 5), datetime.time(13, 10), datetime.time(13, 10),\n",
       "       datetime.time(13, 15), datetime.time(13, 15),\n",
       "       datetime.time(13, 15), datetime.time(13, 15),\n",
       "       datetime.time(13, 20), datetime.time(13, 20),\n",
       "       datetime.time(13, 25), datetime.time(13, 25),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 30), datetime.time(13, 30),\n",
       "       datetime.time(13, 35), datetime.time(13, 35),\n",
       "       datetime.time(13, 40), datetime.time(13, 40),\n",
       "       datetime.time(13, 45), datetime.time(13, 45),\n",
       "       datetime.time(13, 45), datetime.time(13, 45),\n",
       "       datetime.time(13, 50), datetime.time(13, 50),\n",
       "       datetime.time(13, 55), datetime.time(13, 55), datetime.time(14, 0),\n",
       "       datetime.time(14, 0), datetime.time(14, 0), datetime.time(14, 0),\n",
       "       datetime.time(14, 0), datetime.time(14, 0), datetime.time(14, 5),\n",
       "       datetime.time(14, 5), datetime.time(14, 10), datetime.time(14, 10),\n",
       "       datetime.time(14, 15), datetime.time(14, 15),\n",
       "       datetime.time(14, 15), datetime.time(14, 15),\n",
       "       datetime.time(14, 20), datetime.time(14, 20),\n",
       "       datetime.time(14, 25), datetime.time(14, 25),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 30), datetime.time(14, 30),\n",
       "       datetime.time(14, 35), datetime.time(14, 35),\n",
       "       datetime.time(14, 40), datetime.time(14, 40),\n",
       "       datetime.time(14, 45), datetime.time(14, 45),\n",
       "       datetime.time(14, 45), datetime.time(14, 45),\n",
       "       datetime.time(14, 50), datetime.time(14, 50),\n",
       "       datetime.time(14, 55), datetime.time(14, 55), datetime.time(15, 0),\n",
       "       datetime.time(15, 0), datetime.time(15, 0), datetime.time(15, 0),\n",
       "       datetime.time(15, 0), datetime.time(15, 0), datetime.time(15, 5),\n",
       "       datetime.time(15, 5), datetime.time(15, 10), datetime.time(15, 10),\n",
       "       datetime.time(15, 15), datetime.time(15, 15),\n",
       "       datetime.time(15, 15), datetime.time(15, 15),\n",
       "       datetime.time(15, 20), datetime.time(15, 20),\n",
       "       datetime.time(15, 25), datetime.time(15, 25),\n",
       "       datetime.time(15, 30), datetime.time(15, 30),\n",
       "       datetime.time(15, 35)], dtype=object)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_stocks_thirty.index.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put stock and tweet data together\n",
    "tweets_stocks = pd.concat([running_stocks_thirty, tech_indic_df, tweets_master, articles_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_stocks.to_csv('netfilex_tweets_stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
